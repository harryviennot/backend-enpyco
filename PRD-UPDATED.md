# Backend MVP PRD - G√©n√©rateur de M√©moires (Proof of Concept)

## üéØ Objectif du MVP

Cr√©er un **proof of concept fonctionnel** qui d√©montre la capacit√© √† g√©n√©rer automatiquement un m√©moire technique Word en r√©utilisant le contenu d'anciens m√©moires.

**Scope** : Backend Python uniquement, interface minimale (ligne de commande ou API simple)

**Dur√©e estim√©e** : 2-3 semaines

### ‚ö†Ô∏è Contrainte importante d√©couverte

**Deux types de m√©moires :**

- **60% en format libre** : On peut utiliser notre propre structure (structure Bernadet standard)
- **40% avec trame impos√©e** : Template Word fourni par le client dans le RC qu'il faut remplir

**Pour le MVP** : On se concentre sur le **format libre (60%)** uniquement.  
Le support des trames impos√©es sera ajout√© en Phase 2.

### üìã Structure standard Bernadet (format libre)

Pour les 60% de m√©moires en format libre, nous utilisons cette structure :

1. **PR√âSENTATION DE L'ENTREPRISE**
2. **AUTONOMIE MAT√âRIELLE ET MA√éTRISE DE L'EX√âCUTION**
3. **ORGANISATION (HUMAINES + PARTENAIRES) G√âN√âRALE DE L'OP√âRATION**
4. **M√âTHODES DE CONSTRUCTION**
   - ‚ö†Ô∏è Inclut dessins manuscrits + coupes types (hors scope MVP)
5. **GESTION DE PROJET ET SUIVI D'EX√âCUTION : PLANNING**
6. **QUALIT√â, S√âCURIT√â ET ENVIRONNEMENT (HSE)**
   - Organisation r√©serves de r√©ception
   - Organisation r√©serves de GPA
   - Organisation SAV + d√©lai d'intervention
7. **INSERTION SOCIALE ET ENGAGEMENT RSE**
8. **ANNEXES**

---

## üì¶ Stack technique (minimaliste)

| Composant           | Technologie                     | Pourquoi                                      |
| ------------------- | ------------------------------- | --------------------------------------------- |
| **Backend**         | Python 3.11                     | Rapide √† d√©velopper, excellentes libs         |
| **Framework API**   | FastAPI                         | Simple, rapide, auto-documentation            |
| **Base de donn√©es** | Supabase (PostgreSQL)           | Base compl√®te avec APIs, pas de setup serveur |
| **Vector DB**       | Supabase (pgvector)             | Extension int√©gr√©e dans Supabase              |
| **Stockage**        | Supabase Storage (S3)           | Stockage int√©gr√©, URLs sign√©es                |
| **LLM**             | Claude API (Sonnet 4.5)         | Meilleur pour documents longs                 |
| **Embeddings**      | OpenAI (text-embedding-3-small) | Performant, peu co√ªteux                       |
| **Parsing PDF**     | pypdf                           | Simple et efficace                            |
| **Parsing Word**    | python-docx                     | Standard pour .docx                           |
| **G√©n√©ration Word** | python-docx                     | M√™me lib pour lecture/√©criture                |

---

## üèóÔ∏è Architecture simplifi√©e

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Interface (FastAPI)                 ‚îÇ
‚îÇ  - Upload m√©moires                               ‚îÇ
‚îÇ  - Upload RC + annexes                           ‚îÇ
‚îÇ  - D√©clencher g√©n√©ration                         ‚îÇ
‚îÇ  - T√©l√©charger r√©sultat                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Services Python                     ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ   Parser     ‚îÇ  ‚îÇ     RAG      ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  (PDF/Word)  ‚îÇ  ‚îÇ  (pgvector)  ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ   Generator  ‚îÇ  ‚îÇ   Exporter   ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  (Claude)    ‚îÇ  ‚îÇ  (python-docx)‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ        ‚îÇ        ‚îÇ
        ‚ñº        ‚ñº        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Supabase ‚îÇ ‚îÇOpenAI‚îÇ ‚îÇ  Claude  ‚îÇ
‚îÇ          ‚îÇ ‚îÇEmbed ‚îÇ ‚îÇ   API    ‚îÇ
‚îÇ - Postgre‚îÇ ‚îÇ API  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ - pgvector‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ - Storage‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ Structure du projet

```
memoir-generator/
‚îú‚îÄ‚îÄ main.py                 # Point d'entr√©e FastAPI
‚îú‚îÄ‚îÄ config.py               # Configuration (API keys, Supabase)
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py          # Pydantic schemas
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ supabase.py         # Client Supabase
‚îÇ   ‚îú‚îÄ‚îÄ parser.py           # Parse PDF/DOCX
‚îÇ   ‚îú‚îÄ‚îÄ rag.py              # RAG avec pgvector
‚îÇ   ‚îú‚îÄ‚îÄ generator.py        # G√©n√©ration avec Claude
‚îÇ   ‚îî‚îÄ‚îÄ exporter.py         # Export Word
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ helpers.py          # Fonctions utilitaires
‚îÇ
‚îî‚îÄ‚îÄ templates/
    ‚îî‚îÄ‚îÄ template.docx       # Template Word de base
```

---

## üóÑÔ∏è Base de donn√©es (Supabase PostgreSQL)

### Schema minimaliste

```sql
-- Extension pgvector pour les embeddings
CREATE EXTENSION IF NOT EXISTS vector;

-- Table des m√©moires r√©f√©rence
CREATE TABLE memoires (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    filename VARCHAR(255) NOT NULL,
    storage_path VARCHAR(500) NOT NULL,  -- Chemin dans Supabase Storage
    client VARCHAR(255),
    year INTEGER,
    indexed BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Table des projets
CREATE TABLE projects (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    rc_storage_path VARCHAR(500),
    rc_context TEXT,
    status VARCHAR(50) DEFAULT 'draft',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Table des sections g√©n√©r√©es
CREATE TABLE sections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    section_type VARCHAR(100) NOT NULL,
    title VARCHAR(255) NOT NULL,
    content TEXT,
    order_num INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Table des chunks pour RAG
CREATE TABLE document_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    memoire_id UUID NOT NULL REFERENCES memoires(id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    embedding vector(1536),  -- OpenAI embeddings dimension
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Index pour recherche vectorielle
CREATE INDEX ON document_chunks USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- Index pour performance
CREATE INDEX idx_chunks_memoire ON document_chunks(memoire_id);
CREATE INDEX idx_sections_project ON sections(project_id, order_num);
```

---

## üîå API Endpoints (FastAPI)

### 1. Upload de m√©moires r√©f√©rence

```python
POST /memoires/upload
Content-Type: multipart/form-data

Body:
- file: File (PDF ou DOCX)
- client: str (optionnel)
- year: int (optionnel)

Response:
{
    "id": 1,
    "filename": "memoire_toulouse.pdf",
    "status": "uploaded",
    "indexed": false
}
```

### 2. Indexer un m√©moire

```python
POST /memoires/{id}/index

Response:
{
    "id": 1,
    "status": "indexed",
    "chunks_created": 45
}
```

### 3. Cr√©er un projet

```python
POST /projects

Body:
{
    "name": "Bande Infra SNCF"
}

Response:
{
    "id": 1,
    "name": "Bande Infra SNCF",
    "status": "draft"
}
```

### 4. Upload RC et annexes

```python
POST /projects/{id}/upload-rc
Content-Type: multipart/form-data

Body:
- file: File (PDF du RC)

Response:
{
    "project_id": 1,
    "rc_uploaded": true
}
```

### 5. G√©n√©rer le m√©moire

```python
POST /projects/{id}/generate

Body:
{
    "memoire_ids": [1, 2],  # IDs des m√©moires r√©f√©rence
    "sections": [
        "presentation",
        "organisation",
        "methodologie",
        "moyens_humains",
        "moyens_materiels"
    ]
}

Response:
{
    "project_id": 1,
    "status": "generating",
    "estimated_time": "3 minutes"
}
```

### 6. T√©l√©charger le m√©moire

```python
GET /projects/{id}/download

Response: File (DOCX)
```

---

## üõ†Ô∏è Impl√©mentation des services

### 1. Parser Service (`services/parser.py`)

```python
from pypdf import PdfReader
from docx import Document
from typing import List, Dict

class ParserService:
    """Parse PDF et DOCX pour extraire le texte."""

    def parse_pdf(self, filepath: str) -> Dict[str, any]:
        """
        Parse un PDF et retourne le texte structur√©.
        """
        reader = PdfReader(filepath)
        sections = []

        for page_num, page in enumerate(reader.pages, 1):
            text = page.extract_text()
            sections.append({
                'page': page_num,
                'text': text
            })

        full_text = '\n\n'.join(s['text'] for s in sections)

        return {
            'sections': sections,
            'full_text': full_text,
            'page_count': len(reader.pages)
        }

    def parse_docx(self, filepath: str) -> Dict[str, any]:
        """
        Parse un DOCX et retourne le texte structur√©.
        """
        doc = Document(filepath)
        sections = []
        current_section = {'title': 'Introduction', 'content': []}

        for para in doc.paragraphs:
            # D√©tecter les titres
            if para.style.name.startswith('Heading'):
                if current_section['content']:
                    sections.append(current_section)
                current_section = {
                    'title': para.text,
                    'content': []
                }
            else:
                current_section['content'].append(para.text)

        # Ajouter la derni√®re section
        if current_section['content']:
            sections.append(current_section)

        full_text = '\n\n'.join(
            f"{s['title']}\n" + '\n'.join(s['content'])
            for s in sections
        )

        return {
            'sections': sections,
            'full_text': full_text,
            'paragraph_count': len(doc.paragraphs)
        }

    def chunk_text(self, text: str, chunk_size: int = 500) -> List[str]:
        """
        D√©coupe le texte en chunks pour le RAG.
        Simple d√©coupe par caract√®res avec overlap.
        """
        chunks = []
        overlap = 100

        for i in range(0, len(text), chunk_size - overlap):
            chunk = text[i:i + chunk_size]
            if chunk.strip():
                chunks.append(chunk.strip())

        return chunks
```

---

### 2. RAG Service (`services/rag.py`)

```python
from openai import OpenAI
from typing import List, Dict
from services.supabase import get_supabase

class RAGService:
    """Service de RAG avec Supabase pgvector et OpenAI embeddings."""

    def __init__(self, openai_api_key: str):
        self.openai_client = OpenAI(api_key=openai_api_key)
        self.supabase = get_supabase()

    def generate_embedding(self, text: str) -> List[float]:
        """
        G√©n√®re un embedding avec OpenAI.
        """
        response = self.openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding

    def index_memoire(self, memoire_id: str, chunks: List[str], metadata: Dict) -> int:
        """
        Indexe un m√©moire dans Supabase avec pgvector.
        """
        chunks_data = []

        for i, chunk in enumerate(chunks):
            # G√©n√©rer l'embedding
            embedding = self.generate_embedding(chunk)

            chunk_data = {
                'memoire_id': memoire_id,
                'content': chunk,
                'embedding': embedding,
                'metadata': {
                    'chunk_index': i,
                    **metadata
                }
            }
            chunks_data.append(chunk_data)

        # Insertion batch dans Supabase
        result = self.supabase.table('document_chunks').insert(chunks_data).execute()

        return len(chunks_data)

    def search(
        self,
        query: str,
        memoire_ids: List[str] = None,
        n_results: int = 10
    ) -> List[Dict]:
        """
        Recherche les chunks les plus pertinents par similarit√© vectorielle.
        """
        # G√©n√©rer l'embedding de la requ√™te
        query_embedding = self.generate_embedding(query)

        # Construire la requ√™te SQL avec pgvector
        # Utilise l'op√©rateur <=> pour distance cosine
        rpc_params = {
            'query_embedding': query_embedding,
            'match_count': n_results
        }

        if memoire_ids:
            rpc_params['memoire_ids'] = memoire_ids

        # Appel √† une fonction PostgreSQL custom (√† cr√©er)
        result = self.supabase.rpc('match_documents', rpc_params).execute()

        return result.data
```

**Fonction PostgreSQL √† cr√©er dans Supabase :**

```sql
-- Cr√©er cette fonction dans le SQL Editor de Supabase
CREATE OR REPLACE FUNCTION match_documents(
    query_embedding vector(1536),
    match_count int DEFAULT 10,
    memoire_ids uuid[] DEFAULT NULL
)
RETURNS TABLE (
    id uuid,
    content text,
    metadata jsonb,
    similarity float
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    SELECT
        document_chunks.id,
        document_chunks.content,
        document_chunks.metadata,
        1 - (document_chunks.embedding <=> query_embedding) as similarity
    FROM document_chunks
    WHERE
        CASE
            WHEN memoire_ids IS NOT NULL THEN memoire_id = ANY(memoire_ids)
            ELSE true
        END
    ORDER BY document_chunks.embedding <=> query_embedding
    LIMIT match_count;
END;
$$;
```

---

### 3. Generator Service (`services/generator.py`)

```python
from anthropic import Anthropic
from typing import List, Dict

class GeneratorService:
    """Service de g√©n√©ration avec Claude."""

    def __init__(self, api_key: str):
        self.client = Anthropic(api_key=api_key)

    def generate_section(
        self,
        section_type: str,
        rc_context: str,
        reference_chunks: List[Dict]
    ) -> str:
        """
        G√©n√®re une section de m√©moire.
        """
        # Construire le contexte des r√©f√©rences
        references_text = "\n\n---\n\n".join(
            f"Extrait de r√©f√©rence {i+1}:\n{chunk['text']}"
            for i, chunk in enumerate(reference_chunks[:5])
        )

        # Construire le prompt
        prompt = self._build_prompt(section_type, rc_context, references_text)

        # Appel √† Claude
        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            temperature=0.7,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )

        return response.content[0].text

    def _build_prompt(self, section_type: str, rc_context: str, references: str) -> str:
        """
        Construit le prompt pour Claude.
        """
        section_descriptions = {
            'presentation_entreprise': 'Pr√©sentation de l\'entreprise (historique, chiffres cl√©s, certifications, implantations)',
            'autonomie_materielle': 'Autonomie mat√©rielle et ma√Ætrise de l\'ex√©cution (√©quipements, capacit√©s, ind√©pendance)',
            'organisation_generale': 'Organisation g√©n√©rale de l\'op√©ration (organigramme humain, partenaires, coordination)',
            'methodes_construction': 'M√©thodes de construction (phasage, techniques, processus de r√©alisation)',
            'gestion_projet_planning': 'Gestion de projet et suivi d\'ex√©cution avec planning (calendrier, jalons, suivi)',
            'qualite_securite_environnement': 'Qualit√©, S√©curit√© et Environnement - HSE (d√©marche QSE, r√©serves, SAV)',
            'insertion_sociale_rse': 'Insertion sociale et engagement RSE (heures d\'insertion, actions sociales, environnement)'
        }

        description = section_descriptions.get(section_type, section_type)

        return f"""Tu es un expert en r√©daction de m√©moires techniques pour le BTP.

**Contexte du projet (extrait du RC) :**
{rc_context}

**Type de section √† g√©n√©rer :** {description}

**Contenu de r√©f√©rence (extraits de m√©moires similaires) :**
{references}

**Instructions :**
1. G√©n√®re une section professionnelle de m√©moire technique
2. R√©utilise les informations factuelles des r√©f√©rences (chiffres, m√©thodes, √©quipements)
3. Adapte le contenu au contexte du RC
4. Utilise un ton professionnel mais accessible
5. Privil√©gie les tableaux aux longues listes
6. Structure : titre H2, sous-titres H3, paragraphes clairs

**Contraintes :**
- Format : Markdown
- Longueur : 500-1000 mots
- Ne pas inventer de donn√©es, utiliser uniquement les r√©f√©rences

G√©n√®re maintenant la section :"""

    def extract_rc_criteria(self, rc_text: str) -> str:
        """
        Extrait les crit√®res cl√©s du RC.
        """
        prompt = f"""Analyse ce R√®glement de Consultation et extrait les crit√®res d'√©valuation principaux du m√©moire technique.

RC :
{rc_text[:3000]}  # Limiter √† 3000 chars pour le MVP

Liste uniquement les 5-7 crit√®res les plus importants, de mani√®re concise."""

        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=500,
            temperature=0.3,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )

        return response.content[0].text
```

---

### 4. Exporter Service (`services/exporter.py`)

```python
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
import markdown
from bs4 import BeautifulSoup
from typing import List, Dict

class ExporterService:
    """Service d'export vers Word."""

    def __init__(self, template_path: str = "./templates/template.docx"):
        self.template_path = template_path

    def create_memoire(
        self,
        project_name: str,
        sections: List[Dict]
    ) -> str:
        """
        Cr√©e un document Word complet.

        sections: [
            {
                'title': 'Pr√©sentation',
                'content': 'contenu markdown...'
            },
            ...
        ]
        """
        # Charger le template ou cr√©er un nouveau doc
        try:
            doc = Document(self.template_path)
        except:
            doc = Document()
            self._apply_default_styles(doc)

        # Titre du m√©moire
        doc.add_heading(f"M√©moire Technique - {project_name}", level=0)
        doc.add_page_break()

        # Ajouter chaque section
        for section in sections:
            self._add_section(doc, section['title'], section['content'])
            doc.add_page_break()

        # Sauvegarder
        output_path = f"./data/output_{project_name.replace(' ', '_')}.docx"
        doc.save(output_path)

        return output_path

    def _add_section(self, doc: Document, title: str, markdown_content: str):
        """
        Ajoute une section au document.
        """
        # Titre de section
        doc.add_heading(title, level=1)

        # Convertir Markdown en HTML
        html = markdown.markdown(markdown_content, extensions=['tables'])
        soup = BeautifulSoup(html, 'html.parser')

        # Parser et ajouter le contenu
        for element in soup.find_all(['h2', 'h3', 'p', 'ul', 'ol', 'table']):
            if element.name == 'h2':
                doc.add_heading(element.text, level=2)
            elif element.name == 'h3':
                doc.add_heading(element.text, level=3)
            elif element.name == 'p':
                doc.add_paragraph(element.text)
            elif element.name in ['ul', 'ol']:
                for li in element.find_all('li'):
                    doc.add_paragraph(li.text, style='List Bullet')
            elif element.name == 'table':
                self._add_table(doc, element)

    def _add_table(self, doc: Document, html_table):
        """
        Ajoute un tableau au document.
        """
        rows = html_table.find_all('tr')
        if not rows:
            return

        # Compter les colonnes
        cols = len(rows[0].find_all(['th', 'td']))

        # Cr√©er le tableau
        table = doc.add_table(rows=len(rows), cols=cols)
        table.style = 'Light Grid Accent 1'

        # Remplir le tableau
        for i, row in enumerate(rows):
            cells = row.find_all(['th', 'td'])
            for j, cell in enumerate(cells):
                table.rows[i].cells[j].text = cell.text.strip()

    def _apply_default_styles(self, doc: Document):
        """
        Applique les styles par d√©faut (style Bernadet simplifi√©).
        """
        # Style Heading 1
        h1 = doc.styles['Heading 1']
        h1.font.name = 'Arial'
        h1.font.size = Pt(18)
        h1.font.bold = True
        h1.font.color.rgb = RGBColor(46, 80, 144)  # Bleu

        # Style Heading 2
        h2 = doc.styles['Heading 2']
        h2.font.name = 'Arial'
        h2.font.size = Pt(14)
        h2.font.color.rgb = RGBColor(120, 180, 90)  # Vert

        # Style Normal
        normal = doc.styles['Normal']
        normal.font.name = 'Arial'
        normal.font.size = Pt(11)
```

---

---

### Supabase Service (`services/supabase.py`)

```python
from supabase import create_client, Client
from config import Config

_supabase_client: Client = None

def get_supabase() -> Client:
    """
    Singleton pour le client Supabase.
    """
    global _supabase_client

    if _supabase_client is None:
        _supabase_client = create_client(
            Config.SUPABASE_URL,
            Config.SUPABASE_KEY
        )

    return _supabase_client

class SupabaseService:
    """Service pour interagir avec Supabase."""

    def __init__(self):
        self.client = get_supabase()

    # === STORAGE ===

    def upload_file(self, bucket: str, path: str, file_data: bytes) -> str:
        """
        Upload un fichier dans Supabase Storage.
        Retourne le chemin du fichier.
        """
        result = self.client.storage.from_(bucket).upload(
            path=path,
            file=file_data,
            file_options={"content-type": "application/octet-stream"}
        )

        return path

    def get_public_url(self, bucket: str, path: str) -> str:
        """
        G√©n√®re une URL publique pour un fichier.
        """
        return self.client.storage.from_(bucket).get_public_url(path)

    def download_file(self, bucket: str, path: str) -> bytes:
        """
        T√©l√©charge un fichier depuis Supabase Storage.
        """
        result = self.client.storage.from_(bucket).download(path)
        return result

    # === DATABASE ===

    def create_memoire(self, filename: str, storage_path: str, client: str = None, year: int = None) -> str:
        """
        Cr√©e un enregistrement de m√©moire.
        Retourne l'UUID.
        """
        data = {
            'filename': filename,
            'storage_path': storage_path,
            'client': client,
            'year': year
        }

        result = self.client.table('memoires').insert(data).execute()
        return result.data[0]['id']

    def get_memoire(self, memoire_id: str) -> dict:
        """
        R√©cup√®re un m√©moire par son ID.
        """
        result = self.client.table('memoires').select('*').eq('id', memoire_id).execute()
        return result.data[0] if result.data else None

    def mark_memoire_indexed(self, memoire_id: str):
        """
        Marque un m√©moire comme index√©.
        """
        self.client.table('memoires').update({'indexed': True}).eq('id', memoire_id).execute()

    def list_memoires(self) -> list:
        """
        Liste tous les m√©moires.
        """
        result = self.client.table('memoires').select('*').order('created_at', desc=True).execute()
        return result.data

    def create_project(self, name: str) -> str:
        """
        Cr√©e un nouveau projet.
        Retourne l'UUID.
        """
        data = {'name': name}
        result = self.client.table('projects').insert(data).execute()
        return result.data[0]['id']

    def get_project(self, project_id: str) -> dict:
        """
        R√©cup√®re un projet par son ID.
        """
        result = self.client.table('projects').select('*').eq('id', project_id).execute()
        return result.data[0] if result.data else None

    def update_project_rc(self, project_id: str, rc_storage_path: str, rc_context: str):
        """
        Met √† jour le RC d'un projet.
        """
        data = {
            'rc_storage_path': rc_storage_path,
            'rc_context': rc_context
        }
        self.client.table('projects').update(data).eq('id', project_id).execute()

    def update_project_status(self, project_id: str, status: str):
        """
        Met √† jour le statut d'un projet.
        """
        self.client.table('projects').update({'status': status}).eq('id', project_id).execute()

    def list_projects(self) -> list:
        """
        Liste tous les projets.
        """
        result = self.client.table('projects').select('*').order('created_at', desc=True).execute()
        return result.data

    def create_section(self, project_id: str, section_type: str, title: str, content: str, order_num: int) -> str:
        """
        Cr√©e une section g√©n√©r√©e.
        Retourne l'UUID.
        """
        data = {
            'project_id': project_id,
            'section_type': section_type,
            'title': title,
            'content': content,
            'order_num': order_num
        }
        result = self.client.table('sections').insert(data).execute()
        return result.data[0]['id']

    def get_sections(self, project_id: str) -> list:
        """
        R√©cup√®re toutes les sections d'un projet.
        """
        result = self.client.table('sections').select('*').eq('project_id', project_id).order('order_num').execute()
        return result.data
```

---

## üöÄ API Routes (FastAPI)

### `main.py`

```python
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import FileResponse
from typing import List
import tempfile
import os

from services.parser import ParserService
from services.rag import RAGService
from services.generator import GeneratorService
from services.exporter import ExporterService
from services.supabase import SupabaseService
from config import Config

app = FastAPI(title="Memoir Generator MVP")

# Services
parser = ParserService()
rag = RAGService(openai_api_key=Config.OPENAI_API_KEY)
generator = GeneratorService(api_key=Config.CLAUDE_API_KEY)
exporter = ExporterService()
supabase = SupabaseService()

# === M√âMOIRES R√âF√âRENCE ===

@app.post("/memoires/upload")
async def upload_memoire(
    file: UploadFile = File(...),
    client: str = None,
    year: int = None
):
    """Upload un m√©moire de r√©f√©rence."""

    # V√©rifier l'extension
    if not file.filename.endswith(('.pdf', '.docx')):
        raise HTTPException(400, "Format non support√©. PDF ou DOCX uniquement.")

    # Lire le fichier
    file_data = await file.read()

    # Upload vers Supabase Storage
    storage_path = f"memoires/{file.filename}"
    supabase.upload_file('documents', storage_path, file_data)

    # Cr√©er l'enregistrement en base
    memoire_id = supabase.create_memoire(file.filename, storage_path, client, year)

    return {
        "id": memoire_id,
        "filename": file.filename,
        "status": "uploaded",
        "indexed": False
    }

@app.post("/memoires/{memoire_id}/index")
async def index_memoire(memoire_id: str):
    """Indexe un m√©moire pour le RAG."""

    memoire = supabase.get_memoire(memoire_id)
    if not memoire:
        raise HTTPException(404, "M√©moire non trouv√©")

    # T√©l√©charger le fichier depuis Supabase Storage
    file_data = supabase.download_file('documents', memoire['storage_path'])

    # Sauvegarder temporairement
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(memoire['filename'])[1]) as tmp:
        tmp.write(file_data)
        tmp_path = tmp.name

    try:
        # Parser le fichier
        if memoire['filename'].endswith('.pdf'):
            parsed = parser.parse_pdf(tmp_path)
        else:
            parsed = parser.parse_docx(tmp_path)

        # Chunker le texte
        chunks = parser.chunk_text(parsed['full_text'])

        # Indexer dans pgvector
        metadata = {
            'filename': memoire['filename'],
            'client': memoire['client'],
            'year': memoire['year']
        }
        chunks_count = rag.index_memoire(memoire_id, chunks, metadata)

        # Mettre √† jour la base
        supabase.mark_memoire_indexed(memoire_id)

        return {
            "id": memoire_id,
            "status": "indexed",
            "chunks_created": chunks_count
        }
    finally:
        # Nettoyer le fichier temporaire
        os.unlink(tmp_path)

@app.get("/memoires")
async def list_memoires():
    """Liste tous les m√©moires."""
    return supabase.list_memoires()

# === PROJETS ===

@app.post("/projects")
async def create_project(name: str):
    """Cr√©e un nouveau projet."""
    project_id = supabase.create_project(name)
    return {
        "id": project_id,
        "name": name,
        "status": "draft"
    }

@app.post("/projects/{project_id}/upload-rc")
async def upload_rc(project_id: str, file: UploadFile = File(...)):
    """Upload le RC du projet."""

    project = supabase.get_project(project_id)
    if not project:
        raise HTTPException(404, "Projet non trouv√©")

    # Lire le fichier
    file_data = await file.read()

    # Upload vers Supabase Storage
    storage_path = f"projects/{project_id}/rc.pdf"
    supabase.upload_file('documents', storage_path, file_data)

    # Sauvegarder temporairement pour parser
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp:
        tmp.write(file_data)
        tmp_path = tmp.name

    try:
        # Parser pour extraire contexte
        parsed = parser.parse_pdf(tmp_path)
        rc_context = parsed['full_text'][:2000]  # Premiers 2000 chars

        # Mettre √† jour le projet
        supabase.update_project_rc(project_id, storage_path, rc_context)

        return {
            "project_id": project_id,
            "rc_uploaded": True
        }
    finally:
        os.unlink(tmp_path)

@app.post("/projects/{project_id}/generate")
async def generate_memoire(
    project_id: str,
    memoire_ids: List[str],
    sections: List[str]
):
    """G√©n√®re le m√©moire technique."""

    project = supabase.get_project(project_id)
    if not project:
        raise HTTPException(404, "Projet non trouv√©")

    if not project['rc_storage_path']:
        raise HTTPException(400, "RC non upload√©")

    # RC context
    rc_context = project['rc_context'] or "Projet de construction"

    # G√©n√©rer chaque section
    generated_sections = []

    for i, section_type in enumerate(sections, 1):
        # Recherche RAG
        query = f"{section_type} organisation chantier m√©thodologie"
        chunks = rag.search(query, memoire_ids, n_results=10)

        # G√©n√©ration
        content = generator.generate_section(
            section_type=section_type,
            rc_context=rc_context,
            reference_chunks=chunks
        )

        # Sauvegarder en base
        section_id = supabase.create_section(
            project_id=project_id,
            section_type=section_type,
            title=section_type.replace('_', ' ').title(),
            content=content,
            order_num=i
        )

        generated_sections.append({
            'id': section_id,
            'type': section_type,
            'title': section_type.replace('_', ' ').title()
        })

    # Marquer le projet comme pr√™t
    supabase.update_project_status(project_id, 'ready')

    return {
        "project_id": project_id,
        "status": "ready",
        "sections": generated_sections
    }

@app.get("/projects/{project_id}/download")
async def download_memoire(project_id: str):
    """T√©l√©charge le m√©moire g√©n√©r√©."""

    project = supabase.get_project(project_id)
    if not project:
        raise HTTPException(404, "Projet non trouv√©")

    # R√©cup√©rer les sections
    sections = supabase.get_sections(project_id)

    if not sections:
        raise HTTPException(400, "Aucune section g√©n√©r√©e")

    # Cr√©er le document Word
    output_path = exporter.create_memoire(
        project_name=project['name'],
        sections=sections
    )

    return FileResponse(
        output_path,
        media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        filename=f"memoire_{project['name'].replace(' ', '_')}.docx"
    )

@app.get("/projects")
async def list_projects():
    """Liste tous les projets."""
    return supabase.list_projects()

# === HEALTH CHECK ===

@app.get("/health")
async def health_check():
    return {"status": "ok"}
```

---

## ‚öôÔ∏è Configuration (`config.py`)

```python
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    # API Keys
    CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

    # Supabase
    SUPABASE_URL = os.getenv('SUPABASE_URL')
    SUPABASE_KEY = os.getenv('SUPABASE_KEY')

    # Template
    TEMPLATE_PATH = './templates/template.docx'
```

---

## üì¶ Requirements (`requirements.txt`)

```txt
# Web framework
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# Supabase
supabase==2.3.0

# Document processing
pypdf==3.17.1
python-docx==1.1.0
beautifulsoup4==4.12.2
markdown==3.5.1

# LLM & Embeddings
anthropic==0.7.8
openai==1.6.1

# Utils
python-dotenv==1.0.0
```

---

## üöÄ Installation et lancement

### 1. Setup Supabase

```bash
# 1. Cr√©er un compte sur supabase.com
# 2. Cr√©er un nouveau projet
# 3. Dans le SQL Editor, ex√©cuter le script de cr√©ation des tables (voir section Database)
# 4. Activer pgvector : Extensions ‚Üí rechercher "vector" ‚Üí Enable
# 5. Cr√©er un bucket "documents" dans Storage
# 6. Copier l'URL et la cl√© API du projet
```

### 2. Installation locale

```bash
# Cr√©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sur Windows

# Installer les d√©pendances
pip install -r requirements.txt

# Cr√©er le dossier templates
mkdir -p templates
```

### 3. Configuration

```bash
# Cr√©er le fichier .env
cat > .env << EOF
CLAUDE_API_KEY=sk-ant-your-key-here
OPENAI_API_KEY=sk-your-openai-key-here
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-anon-key-here
EOF
```

### 4. Lancer le serveur

```bash
uvicorn main:app --reload --port 8000
```

L'API sera accessible sur `http://localhost:8000`

Documentation auto-g√©n√©r√©e : `http://localhost:8000/docs`

---

## üìù Workflow d'utilisation (MVP)

### √âtape 1 : Uploader des m√©moires r√©f√©rence

```bash
curl -X POST "http://localhost:8000/memoires/upload" \
  -F "file=@memoire_toulouse.pdf" \
  -F "client=Toulouse Metropole" \
  -F "year=2024"

# R√©ponse :
# {"id": 1, "filename": "memoire_toulouse.pdf", "status": "uploaded", "indexed": false}
```

### √âtape 2 : Indexer les m√©moires

```bash
curl -X POST "http://localhost:8000/memoires/1/index"

# R√©ponse :
# {"id": 1, "status": "indexed", "chunks_created": 45}
```

### √âtape 3 : Cr√©er un projet

```bash
curl -X POST "http://localhost:8000/projects?name=Bande%20Infra%20SNCF"

# R√©ponse :
# {"id": 1, "name": "Bande Infra SNCF", "status": "draft"}
```

### √âtape 4 : Uploader le RC

```bash
curl -X POST "http://localhost:8000/projects/1/upload-rc" \
  -F "file=@rc_sncf.pdf"

# R√©ponse :
# {"project_id": 1, "rc_uploaded": true}
```

### √âtape 5 : G√©n√©rer le m√©moire

```bash
curl -X POST "http://localhost:8000/projects/1/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "memoire_ids": [1, 2],
    "sections": [
      "presentation",
      "organisation",
      "methodologie",
      "moyens_humains",
      "moyens_materiels"
    ]
  }'

# R√©ponse :
# {
#   "project_id": 1,
#   "status": "ready",
#   "sections": [...]
# }
```

### √âtape 6 : T√©l√©charger le r√©sultat

```bash
curl -X GET "http://localhost:8000/projects/1/download" \
  --output memoire.docx
```

---

## üéØ P√©rim√®tre MVP

### ‚úÖ Ce qui est inclus

- Upload de m√©moires r√©f√©rence (PDF/DOCX)
- Parsing et chunking automatique
- Indexation avec RAG (ChromaDB)
- Upload du RC
- G√©n√©ration de 5 sections de base
- Export Word avec style minimal
- API REST compl√®te
- Base de donn√©es SQLite

### ‚ùå Ce qui n'est PAS inclus (pour plus tard)

- Interface web (frontend)
- Authentification utilisateur
- Upload d'images/annexes
- R√©g√©n√©ration de sections
- Versioning
- Templates Word personnalisables
- Multi-utilisateurs
- Monitoring/logs
- Tests automatis√©s
- D√©ploiement production

---

## üìä Estimation de charge

### D√©veloppement

| T√¢che                      | Temps estim√©  |
| -------------------------- | ------------- |
| Setup projet + structure   | 0.5 jour      |
| Parser service             | 1 jour        |
| RAG service (ChromaDB)     | 1 jour        |
| Generator service (Claude) | 1 jour        |
| Exporter service (Word)    | 1 jour        |
| API routes (FastAPI)       | 1 jour        |
| Database layer             | 0.5 jour      |
| Tests manuels              | 1 jour        |
| Documentation              | 0.5 jour      |
| **Total**                  | **7-8 jours** |

### Co√ªts

| Poste                          | Co√ªt        |
| ------------------------------ | ----------- |
| D√©veloppement (1 dev, 8 jours) | ~4 000‚Ç¨     |
| Supabase (Free tier)           | 0‚Ç¨          |
| Claude API (tests)             | ~20‚Ç¨        |
| OpenAI Embeddings (tests)      | ~5‚Ç¨         |
| **Total MVP**                  | **~4 025‚Ç¨** |

**Note** : Supabase Free tier inclut :

- 500 MB de stockage
- 2 GB de bande passante
- 50 000 utilisateurs actifs mensuels
- Largement suffisant pour un MVP

---

## üß™ Tests du MVP

### Test complet

```python
# test_mvp.py
import requests
import os

BASE_URL = "http://localhost:8000"

# 1. Upload m√©moire
with open("test_data/memoire1.pdf", "rb") as f:
    response = requests.post(
        f"{BASE_URL}/memoires/upload",
        files={"file": f},
        data={"client": "Test Client", "year": 2024}
    )
    memoire_id = response.json()["id"]
    print(f"‚úì M√©moire upload√©: {memoire_id}")

# 2. Indexer
response = requests.post(f"{BASE_URL}/memoires/{memoire_id}/index")
print(f"‚úì M√©moire index√©: {response.json()['chunks_created']} chunks")

# 3. Cr√©er projet
response = requests.post(
    f"{BASE_URL}/projects",
    params={"name": "Test Project"}
)
project_id = response.json()["id"]
print(f"‚úì Projet cr√©√©: {project_id}")

# 4. Upload RC
with open("test_data/rc.pdf", "rb") as f:
    response = requests.post(
        f"{BASE_URL}/projects/{project_id}/upload-rc",
        files={"file": f}
    )
    print(f"‚úì RC upload√©")

# 5. G√©n√©rer
response = requests.post(
    f"{BASE_URL}/projects/{project_id}/generate",
    json={
        "memoire_ids": [memoire_id],
        "sections": ["presentation", "methodologie"]
    }
)
print(f"‚úì M√©moire g√©n√©r√©: {len(response.json()['sections'])} sections")

# 6. T√©l√©charger
response = requests.get(f"{BASE_URL}/projects/{project_id}/download")
with open("output_test.docx", "wb") as f:
    f.write(response.content)
print(f"‚úì M√©moire t√©l√©charg√©: output_test.docx")
```

---

## üîÑ Prochaines √©tapes (apr√®s MVP)

1. **Support des trames impos√©es (40% des m√©moires)**
   - Parser les templates Word fournis dans le RC
   - Identifier les zones √† remplir (form fields, tableaux, etc.)
   - Remplir automatiquement ces zones avec le contenu g√©n√©r√©
2. **Interface web simple** (Streamlit ou Gradio)

3. **Am√©lioration du chunking** (pr√©servation de structure)

4. **Templates Word** professionnels (style Bernadet avec charte graphique)

5. **R√©g√©n√©ration de sections**

6. **Upload d'images/annexes**

7. **G√©n√©ration d'organigrammes** (qui changent par projet !)

8. **Interface d'√©dition**

9. **Multi-utilisateurs**

10. **D√©ploiement cloud**

### üí° Potentiel commercial

> "Tous les lots (√©lectricien, plaquiste, plombier, etc) sont soumis √† cet exercice impos√©. [...] il y a du potentiel..."

**Opportunit√© identifi√©e :** Ce besoin existe pour **tous les corps de m√©tier du BTP**. Potentiel de commercialisation important si le produit fonctionne bien.

---

## üìö Documentation API

La documentation interactive est disponible automatiquement via FastAPI :

- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

---

## ‚úÖ Crit√®res de succ√®s du MVP

Le MVP sera consid√©r√© comme r√©ussi si :

1. ‚úÖ On peut uploader et indexer des m√©moires PDF/DOCX
2. ‚úÖ On peut cr√©er un projet et uploader un RC
3. ‚úÖ La g√©n√©ration produit des sections coh√©rentes
4. ‚úÖ Le document Word export√© est lisible et structur√©
5. ‚úÖ Le temps de g√©n√©ration est < 5 minutes
6. ‚úÖ Le contenu r√©utilise les r√©f√©rences pertinentes

---

**Ce MVP peut √™tre d√©velopp√© en 7-8 jours et permettra de valider l'approche technique avant d'investir dans une solution compl√®te.**
